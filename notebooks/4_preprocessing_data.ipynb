{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65fe139-f425-481a-9e02-873d93bcb487",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87310109-6729-4d74-8295-1bcbd91956a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab48355-d0cc-4fc6-adc9-33fc49570a2a",
   "metadata": {},
   "source": [
    "## Lectura y preparación inicial de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19a5381-b5fc-449f-9501-7a57d00e0883",
   "metadata": {},
   "source": [
    "### Cargar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a7e575-03dd-435f-b4e0-9cbcb056e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/raw/data.csv\"\n",
    "df = pd.read_csv(file_path, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4cdfe2-605f-4c8d-8ebe-909d8d06cb33",
   "metadata": {},
   "source": [
    "### Preparar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca53ebc-cc84-47ba-b3e6-2ebd2ec7e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nombres cortos para las características\n",
    "feature_names = [f'feat{str(i+1).zfill(2)}' for i in range(30)]\n",
    "\n",
    "# Eliminar columna ID y asignar nombres a las columnas\n",
    "df = df.drop([0], axis=1)  # El ID no aporta información\n",
    "df.columns = ['diagnosis'] + feature_names\n",
    "\n",
    "# Mapear diagnóstico de M/B a 0/1\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 0, 'B': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51310569-ffe4-4ef3-be50-e6143509268e",
   "metadata": {},
   "source": [
    "## Dividir en características (X) y target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d4d105-26e8-4c37-8b88-fa3ed964bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_names]\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286c719e-02bd-43a1-8844-01a219faa84f",
   "metadata": {},
   "source": [
    "## Dividir en conjuntos de entrenamiento y test\n",
    "- Proponemos estos porcentajes para la división `train - test`: **80% - 20%**\n",
    "- Establecemos los porcentajes como parámetros.\n",
    "- Esta división se realiza habitualmente con esta función de la librería 'sklearn'\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "```\n",
    "Esta implementación replica de forma \"manual\" la funcionalidad de `train_test_split` de `sklearn` con las siguientes características:\n",
    "- Permite definir el tamaño del conjunto de test (test_size)\n",
    "- Implementa la opción de estratificación (stratify) para mantener la proporción de clases\n",
    "- Permite fijar una semilla aleatoria (random_state) para asegurar reproducibilidad\n",
    "- Funciona tanto con arrays de NumPy como con listas Python\n",
    "\n",
    "La implementación estratificada funciona así:\n",
    "- Agrupa los índices por clase\n",
    "- Para cada clase, mezcla aleatoriamente sus índices\n",
    "- Divide los índices de cada clase según la proporción deseada\n",
    "- Combina los índices para formar los conjuntos de entrenamiento y test\n",
    "\n",
    "La implementación sin estratificación simplemente mezcla todos los índices y los divide según la proporción deseada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f1c91b-bb1c-4a6e-af3b-af0fbad2d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def manual_train_test_split(X, y, test_size=0.2, random_state=None, stratify=None):\n",
    "    \"\"\"\n",
    "    Implementación manual de train_test_split\n",
    "    \n",
    "    Parámetros:\n",
    "    X : Características\n",
    "    y : Etiquetas o variables objetivo\n",
    "    test_size : Proporción de datos para el conjunto de prueba (por defecto 0.2)\n",
    "    random_state : Semilla para la generación de números aleatorios (por defecto None)\n",
    "    stratify : Array para estratificación (por defecto None)\n",
    "    \n",
    "    Retorna:\n",
    "    X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # Establecer la semilla aleatoria para reproducibilidad\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Asegurarse de que X e y tienen la misma longitud\n",
    "    assert len(X) == len(y), \"X e y deben tener la misma longitud\"\n",
    "    \n",
    "    # Índices de los datos\n",
    "    indices = np.arange(len(X))\n",
    "    \n",
    "    if stratify is not None:\n",
    "        # Implementación con estratificación\n",
    "        # Agrupar índices por clase\n",
    "        indices_por_clase = defaultdict(list)\n",
    "        for i, clase in enumerate(stratify):\n",
    "            indices_por_clase[clase].append(i)\n",
    "        \n",
    "        # Inicializar los índices de train y test\n",
    "        train_indices = []\n",
    "        test_indices = []\n",
    "        \n",
    "        # Para cada clase, dividir los índices según la proporción test_size\n",
    "        for clase, indices_clase in indices_por_clase.items():\n",
    "            # Mezclar los índices de esta clase\n",
    "            indices_clase = np.array(indices_clase)\n",
    "            np.random.shuffle(indices_clase)\n",
    "            \n",
    "            # Calcular cuántos elementos van al conjunto de test\n",
    "            n_test = int(len(indices_clase) * test_size)\n",
    "            \n",
    "            # Dividir los índices\n",
    "            test_indices.extend(indices_clase[:n_test])\n",
    "            train_indices.extend(indices_clase[n_test:])\n",
    "    else:\n",
    "        # Implementación sin estratificación\n",
    "        # Mezclar todos los índices\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        # Calcular cuántos elementos van al conjunto de test\n",
    "        n_test = int(len(indices) * test_size)\n",
    "        \n",
    "        # Dividir los índices\n",
    "        test_indices = indices[:n_test]\n",
    "        train_indices = indices[n_test:]\n",
    "    \n",
    "    # Ordenar los índices (no es estrictamente necesario, pero ayuda a la reproducibilidad)\n",
    "    train_indices = sorted(train_indices)\n",
    "    test_indices = sorted(test_indices)\n",
    "    \n",
    "    # Seleccionar los datos según los índices\n",
    "    import pandas as pd\n",
    "    \n",
    "    if isinstance(X, np.ndarray):\n",
    "        X_train = X[train_indices]\n",
    "        X_test = X[test_indices]\n",
    "    elif isinstance(X, pd.DataFrame):\n",
    "        X_train = X.iloc[train_indices]\n",
    "        X_test = X.iloc[test_indices]\n",
    "    else:\n",
    "        X_train = [X[i] for i in train_indices]\n",
    "        X_test = [X[i] for i in test_indices]\n",
    "    \n",
    "    if isinstance(y, np.ndarray):\n",
    "        y_train = y[train_indices]\n",
    "        y_test = y[test_indices]\n",
    "    elif isinstance(y, pd.Series):\n",
    "        y_train = y.iloc[train_indices]\n",
    "        y_test = y.iloc[test_indices]\n",
    "    else:\n",
    "        y_train = [y[i] for i in train_indices]\n",
    "        y_test = [y[i] for i in test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f464ba-19a1-477a-a693-f59a934091ee",
   "metadata": {},
   "source": [
    "## Aplicando el split estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb52f64-5979-4c0d-bc38-af4244755f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos el parámetro de porcentaje\n",
    "train_size = 0.8\n",
    "test_size = 1 - train_size\n",
    "\n",
    "X_train, X_test, y_train, y_test = manual_train_test_split(\n",
    " X, y, \n",
    " test_size=test_size, \n",
    " random_state=42,\n",
    " stratify=y    # Mantener la proporción de clases en ambos conjuntos\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f610fe-2dfe-4bde-9870-a145cde9c6c9",
   "metadata": {},
   "source": [
    "## Normalización Z-score usando SOLO los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07116e8c-2705-4586-bb9d-37144fb53c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular media y desviación estándar del conjunto de entrenamiento\n",
    "mean_train = X_train.mean()\n",
    "std_train = X_train.std()\n",
    "\n",
    "# Normalizar conjuntos de entrenamiento y test\n",
    "X_train_normalized = (X_train - mean_train) / std_train\n",
    "X_test_normalized = (X_test - mean_train) / std_train\n",
    "\n",
    "# 6. Guardar los parámetros de normalización\n",
    "normalization_params = {\n",
    "    'mean': mean_train,\n",
    "    'std': std_train\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1094dae-3868-40db-a241-a761d8711be9",
   "metadata": {},
   "source": [
    "## Crear directorios si no existen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6cd1997-c4c8-4d1d-8743-4d10007833eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = \"../data/processed\"\n",
    "output_dir = \"../output\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2101fb35-e186-4ecd-b31e-2d74cdd8f2bc",
   "metadata": {},
   "source": [
    "## Guardar los conjuntos normalizados en data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "533715fa-4553-4eef-a6f2-b4282870e61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parámetros de normalización (agrupados por característica) guardados en: ../output/normalization_params.json\n"
     ]
    }
   ],
   "source": [
    "# Conjuntos de entrenamiento\n",
    "train_df = pd.DataFrame(X_train_normalized, columns=feature_names)\n",
    "train_df.insert(0, 'diagnosis', y_train.values)\n",
    "train_df.to_csv(f\"{processed_dir}/train_normalized.csv\", index=False)\n",
    "\n",
    "# Conjuntos de test\n",
    "test_df = pd.DataFrame(X_test_normalized, columns=feature_names)\n",
    "test_df.insert(0, 'diagnosis', y_test.values)\n",
    "test_df.to_csv(f\"{processed_dir}/test_normalized.csv\", index=False)\n",
    "\n",
    "# Guardar los parámetros de normalización en output\n",
    "# Convertir los parámetros a un diccionario para JSON\n",
    "\n",
    "# Reorganizar parámetros por característica\n",
    "params_by_feature = {}\n",
    "\n",
    "# Para cada característica, guardar su media y desviación en un mismo objeto\n",
    "for feature in feature_names:\n",
    "    params_by_feature[feature] = {\n",
    "        'mean': float(mean_train[feature]),  # Convertir a float para asegurar serialización JSON\n",
    "        'std': float(std_train[feature])\n",
    "    }\n",
    "\n",
    "# Guardar los parámetros en formato JSON\n",
    "json_path = f\"{output_dir}/normalization_params.json\"\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(params_by_feature, f, indent=4)\n",
    "\n",
    "print(f\"\\nParámetros de normalización (agrupados por característica) guardados en: {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0b927-64ec-4d0a-a60a-13ae104fb505",
   "metadata": {},
   "source": [
    "## Imprimir información sobre los conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc34b37f-350e-4fe4-9a75-3297db828c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Información sobre la división de datos:\n",
      "Tamaño total del dataset: 569\n",
      "Tamaño del conjunto de entrenamiento: 456\n",
      "Tamaño del conjunto de test: 113\n",
      "\n",
      "Distribución de clases:\n",
      "Conjunto de entrenamiento:\n",
      "diagnosis\n",
      "1    0.627\n",
      "0    0.373\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Conjunto de test:\n",
      "diagnosis\n",
      "1    0.628\n",
      "0    0.372\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Primeras filas del conjunto de entrenamiento normalizado:\n",
      "====  ===========  =========  =========  ========  =========  =========  =========  ==========  ========  ==========  =========  ========  =========  ========  =========  =========  ==========  =========  ========  =========  =========  =========  ==========  =========  =========  =========  =========  =========  ========  =========  =========\n",
      "  ..    diagnosis     feat01     feat02    feat03     feat04     feat05     feat06      feat07    feat08      feat09     feat10    feat11     feat12    feat13     feat14     feat15      feat16     feat17    feat18     feat19     feat20     feat21      feat22     feat23     feat24     feat25     feat26     feat27    feat28     feat29     feat30\n",
      "====  ===========  =========  =========  ========  =========  =========  =========  ==========  ========  ==========  =========  ========  =========  ========  =========  =========  ==========  =========  ========  =========  =========  =========  ==========  =========  =========  =========  =========  =========  ========  =========  =========\n",
      "   0            0   1.11932   -2.04692    1.28955   1.00005    1.50082    3.33527    2.67058    2.52068    2.24026     2.23444   2.36254   -0.561856  2.70176    2.36217   -0.221162   1.32804     0.683406  0.64105    1.19545    0.972292   1.92542   -1.35321     2.34048    2.04609    1.27022    2.67631    2.16682    2.32684   2.81499    1.95814\n",
      "   1            0   1.8485    -0.344413   1.70338   1.91708   -0.834365  -0.501608  -0.0223178  0.547054  -0.004501   -0.897534  0.465066  -0.864194  0.244258   0.702125  -0.603627  -0.710937   -0.434261  0.249775  -0.841838  -0.106566   1.84413   -0.358656    1.5685     1.93424   -0.390209  -0.437791  -0.139265   1.10665  -0.241595   0.271209\n",
      "   2            0   1.59979    0.457309   1.58456   1.57002    0.890316   1.06547    1.37339    2.0281     0.945916   -0.425748  1.16041   -0.770705  0.806203   1.11965   -0.302281   0.81886     0.193135  1.38717    0.244968   0.314679   1.54817   -0.0118702   1.38       1.49574    0.500542   1.10886    0.884573   1.9826    1.18349    0.189912\n",
      "   3            0  -0.737552   0.256879  -0.56323  -0.734967   3.17278    3.45677    1.92915    1.44574    2.89852     4.89605   0.300262  -0.119639  0.266509  -0.278375   0.662026   2.77618     0.775034  1.0846     4.93174    2.19467   -0.256775   0.146801   -0.224695  -0.530404   3.32846    3.98112    2.04424    2.20543   6.17871    5.01245\n",
      "   4            0   1.76936   -1.13462    1.79352   1.83526    0.245122   0.542851   1.38097    1.42265   -0.0155954  -0.590589  1.20032   -0.780583  1.21003    1.12823    1.43738   -0.0571728   0.783624  1.11311   -0.378589   0.535235   1.33349   -1.46117     1.37102    1.25785    0.19786   -0.318168   0.63744    0.74551  -0.879002  -0.419822\n",
      "====  ===========  =========  =========  ========  =========  =========  =========  ==========  ========  ==========  =========  ========  =========  ========  =========  =========  ==========  =========  ========  =========  =========  =========  ==========  =========  =========  =========  =========  =========  ========  =========  =========\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInformación sobre la división de datos:\")\n",
    "print(f\"Tamaño total del dataset: {len(df)}\")\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(X_train)}\")\n",
    "print(f\"Tamaño del conjunto de test: {len(X_test)}\")\n",
    "\n",
    "# Distribución de clases\n",
    "print(\"\\nDistribución de clases:\")\n",
    "print(\"Conjunto de entrenamiento:\")\n",
    "print(y_train.value_counts(normalize=True).round(3))\n",
    "print(\"\\nConjunto de test:\")\n",
    "print(y_test.value_counts(normalize=True).round(3))\n",
    "\n",
    "# Mostrar primeras filas del conjunto de entrenamiento normalizado\n",
    "print(\"\\nPrimeras filas del conjunto de entrenamiento normalizado:\")\n",
    "print(tabulate(train_df.head(), headers='keys', tablefmt='rst', showindex=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
