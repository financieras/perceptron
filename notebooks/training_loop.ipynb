{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "024964c3-e6a6-4903-ad71-dad5c495651d",
   "metadata": {},
   "source": [
    "# Bucle de entrenamiento\n",
    "Implementaremos el bucle de entrenamiento completo y añadiremos algunas visualizaciones para monitorear el proceso.\n",
    "\n",
    "1. Función principal de entrenamiento que incluye:\n",
    "   - Mini-batch gradient descent\n",
    "   - Monitoreo de métricas (costo y precisión)\n",
    "   - Evaluación en conjuntos de entrenamiento y prueba\n",
    "   - Almacenamiento del historial de entrenamiento\n",
    "\n",
    "2. Funciones auxiliares:\n",
    "   - `compute_accuracy`: Calcula la precisión de las predicciones\n",
    "   - `plot_training_history`: Visualiza la evolución del entrenamiento\n",
    "\n",
    "3. Características importantes:\n",
    "   - Usa mini-batches para mejor eficiencia y estabilidad\n",
    "   - Shuffling de datos en cada época\n",
    "   - Monitoreo regular del progreso\n",
    "   - Visualizaciones del proceso de entrenamiento\n",
    "\n",
    "Los hiperparámetros que hemos establecido son:\n",
    "- Learning rate: 0.01\n",
    "- Número de épocas: 2000\n",
    "- Tamaño de batch: 32\n",
    "- Frecuencia de impresión: cada 100 épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe99bd9-2cbe-45bc-83e3-4c9ee7483757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.ft_functions import (\n",
    "    initialize_parameters,\n",
    "    relu, relu_derivative,\n",
    "    sigmoid, sigmoid_derivative\n",
    ")\n",
    "\n",
    "def train_neural_network(X_train, Y_train, X_test, Y_test, layer_dims, \n",
    "                        learning_rate=0.01, num_epochs=2000, batch_size=32, \n",
    "                        print_every=100):\n",
    "    \"\"\"\n",
    "    Entrena la red neuronal\n",
    "    \n",
    "    Args:\n",
    "        X_train, Y_train: Datos de entrenamiento\n",
    "        X_test, Y_test: Datos de prueba\n",
    "        layer_dims: Lista con dimensiones de cada capa\n",
    "        learning_rate: Tasa de aprendizaje\n",
    "        num_epochs: Número de épocas\n",
    "        batch_size: Tamaño del mini-batch\n",
    "        print_every: Cada cuántas épocas imprimir resultados\n",
    "    \n",
    "    Returns:\n",
    "        dict: Historia del entrenamiento\n",
    "        dict: Parámetros finales\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    m = X_train.shape[1]  # número de ejemplos\n",
    "    \n",
    "    # Para almacenar el historial\n",
    "    history = {\n",
    "        'train_cost': [],\n",
    "        'test_cost': [],\n",
    "        'train_accuracy': [],\n",
    "        'test_accuracy': []\n",
    "    }\n",
    "    \n",
    "    # Número de mini-batches\n",
    "    n_batches = max(m // batch_size, 1)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_cost = 0\n",
    "        \n",
    "        # Crear permutación aleatoria de los índices\n",
    "        permutation = np.random.permutation(m)\n",
    "        X_shuffled = X_train[:, permutation]\n",
    "        Y_shuffled = Y_train[:, permutation]\n",
    "        \n",
    "        # Mini-batch training\n",
    "        for batch in range(n_batches):\n",
    "            start_idx = batch * batch_size\n",
    "            end_idx = min((batch + 1) * batch_size, m)\n",
    "            \n",
    "            X_batch = X_shuffled[:, start_idx:end_idx]\n",
    "            Y_batch = Y_shuffled[:, start_idx:end_idx]\n",
    "            \n",
    "            # Forward propagation\n",
    "            cache, A3 = forward_propagation(X_batch, parameters)\n",
    "            \n",
    "            # Calcular costo\n",
    "            batch_cost = compute_cost(A3, Y_batch)\n",
    "            epoch_cost += batch_cost\n",
    "            \n",
    "            # Backward propagation\n",
    "            gradients = backward_propagation(X_batch, Y_batch, parameters, cache)\n",
    "            \n",
    "            # Actualizar parámetros\n",
    "            parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "        \n",
    "        epoch_cost /= n_batches\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            # Evaluar en conjunto de entrenamiento\n",
    "            train_cache, train_predictions = forward_propagation(X_train, parameters)\n",
    "            train_cost = compute_cost(train_predictions, Y_train)\n",
    "            train_accuracy = compute_accuracy(train_predictions, Y_train)\n",
    "            \n",
    "            # Evaluar en conjunto de prueba\n",
    "            test_cache, test_predictions = forward_propagation(X_test, parameters)\n",
    "            test_cost = compute_cost(test_predictions, Y_test)\n",
    "            test_accuracy = compute_accuracy(test_predictions, Y_test)\n",
    "            \n",
    "            # Guardar métricas\n",
    "            history['train_cost'].append(train_cost)\n",
    "            history['test_cost'].append(test_cost)\n",
    "            history['train_accuracy'].append(train_accuracy)\n",
    "            history['test_accuracy'].append(test_accuracy)\n",
    "            \n",
    "            print(f\"Época {epoch}/{num_epochs}\")\n",
    "            print(f\"  Costo entrenamiento: {train_cost:.4f}\")\n",
    "            print(f\"  Precisión entrenamiento: {train_accuracy:.4f}\")\n",
    "            print(f\"  Costo prueba: {test_cost:.4f}\")\n",
    "            print(f\"  Precisión prueba: {test_accuracy:.4f}\")\n",
    "    \n",
    "    return history, parameters\n",
    "\n",
    "def compute_accuracy(predictions, Y):\n",
    "    \"\"\"\n",
    "    Calcula la precisión de las predicciones\n",
    "    \"\"\"\n",
    "    predictions = predictions > 0.5\n",
    "    return np.mean(predictions == Y)\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Visualiza el historial de entrenamiento\n",
    "    \"\"\"\n",
    "    epochs = range(0, len(history['train_cost']))\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Gráfico de costo\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_cost'], label='Entrenamiento')\n",
    "    plt.plot(epochs, history['test_cost'], label='Prueba')\n",
    "    plt.title('Evolución del Costo')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Costo')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Gráfico de precisión\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_accuracy'], label='Entrenamiento')\n",
    "    plt.plot(epochs, history['test_accuracy'], label='Prueba')\n",
    "    plt.title('Evolución de la Precisión')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Precisión')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Cargar datos del notebook anterior\n",
    "# Asumimos que X_train_scaled, X_test_scaled, y_train, y_test están disponibles\n",
    "\n",
    "# Preparar los datos en el formato correcto (asegurarse de que sean matrices 2D)\n",
    "X_train = X_train_scaled.T  # Transponer para tener formato (n_features, n_samples)\n",
    "X_test = X_test_scaled.T\n",
    "Y_train = y_train.reshape(1, -1)  # Reshape para tener formato (1, n_samples)\n",
    "Y_test = y_test.reshape(1, -1)\n",
    "\n",
    "# Definir arquitectura de la red\n",
    "layer_dims = [30, 16, 8, 1]\n",
    "\n",
    "# Entrenar la red\n",
    "history, trained_parameters = train_neural_network(\n",
    "    X_train, Y_train, X_test, Y_test,\n",
    "    layer_dims,\n",
    "    learning_rate=0.01,\n",
    "    num_epochs=2000,\n",
    "    batch_size=32,\n",
    "    print_every=100\n",
    ")\n",
    "\n",
    "# Visualizar el progreso del entrenamiento\n",
    "plot_training_history(history)\n",
    "\n",
    "# Evaluar modelo final\n",
    "_, final_train_predictions = forward_propagation(X_train, trained_parameters)\n",
    "_, final_test_predictions = forward_propagation(X_test, trained_parameters)\n",
    "\n",
    "print(\"\\nResultados finales:\")\n",
    "print(f\"Precisión en entrenamiento: {compute_accuracy(final_train_predictions, Y_train):.4f}\")\n",
    "print(f\"Precisión en prueba: {compute_accuracy(final_test_predictions, Y_test):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
